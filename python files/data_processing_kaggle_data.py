# -*- coding: utf-8 -*-
"""data_processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1csNYO2h4ID_y4qZ4xfRzsg7og4HFpxEm
"""


import pyspark
import json
import re
import string
import csv

from pyspark.sql import SparkSession
sc = pyspark.SparkContext.getOrCreate()

def getHashtags(hashtags):
    hashtag_list = []
    for hashtag in hashtags:
        hashtag_list.append(hashtag["text"])
    return hashtag_list


def preprocess_tweet(text):
    # remove usernames
    nopunc = re.sub('@[^\s]+', '', text)
    # Check characters to see if they are in punctuation
    nopunc = [char for char in nopunc if char not in string.punctuation]
    # Join the characters again to form the string.
    nopunc = ''.join(nopunc)
    # convert text to lower-case
    nopunc = nopunc.lower()
    # remove URLs
    nopunc = re.sub('((www\.[^\s]+)|(https?://[^\s]+)|(http?://[^\s]+))', '', nopunc)
    nopunc = re.sub(r'http\S+', '', nopunc)
    # remove the # in #hashtag
    nopunc = re.sub(r'#([^\s]+)', r'\1', nopunc)
    # replacing the non ascii chars with space
    nopunc = re.sub(r'[^\x00-\x7f]', r' ', nopunc)
    # checkinif string starts with 'rt '
    if (nopunc.startswith("rt ")):
        nopunc = nopunc[3:]
    # removing multiple spaces
    nopunc = re.sub(' +', ' ', nopunc)
    # stripping whitespace
    nopunc = nopunc.strip()
    return nopunc


def getText_Loc_Hashtags(rdd):
    try:
        text = rdd["text"]
        hashtaglist = getHashtags(rdd["entities"]["hashtags"])
        for hashtag in hashtaglist:
            text += " " + hashtag
        text = preprocess_tweet(text)
        return {"text": text, "geo": rdd["geo"], "hashtags": hashtaglist}
    except Exception as e:
        return {}

twitterFilesList = ["data/coronavirus_tweets_20200127.txt", "data/coronavirus_tweets_20200128.txt", "data/coronavirus_tweets_20200128_2.txt",
                         "data/coronavirus_tweets_20200129_1.txt", "data/coronavirus_tweets_20200129_2.txt", "data/coronavirus_tweets_20200129_3.txt",
                         "data/coronavirus_tweets_20200205.txt", "data/coronavirus_tweets_20200302.txt", "data/coronavirus_tweets_20200201.txt",
                         "data/coronavirus_tweets_20200202.txt", "data/coronavirus_tweets_20200203.txt", "data/coronavirus_tweets_20200204_1.txt",
                         "data/coronavirus_tweets_20200204_2.txt"]

for twitter_file in twitterFilesList:
    dfFromText = sc.textFile(twitter_file)
    # dfFromText.take(2)
    dfFromText = dfFromText.filter(lambda x: x != "")
    jsonRDDs = dfFromText.map(lambda x: json.loads(x))

    rdds = jsonRDDs.map(getText_Loc_Hashtags)
    rdds.saveAsTextFile("processed_data/"+twitter_file.split("/")[1])


